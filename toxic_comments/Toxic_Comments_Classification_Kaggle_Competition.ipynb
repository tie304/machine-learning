{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJNc2huK0n3P"
   },
   "source": [
    "# Toxic Comments Classification 96.8% Accuracy Solution - Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpnv8_jv0n3U"
   },
   "source": [
    "In this notebook I'll be compleating the kaggle challenge listed here: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data <br> This challenge is a multi label classifcation problem where I must return the probability of each of the labels: toxic, severe_toxic, obscene,threat,insult,identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "L-eKFTUo0n3Y",
    "outputId": "9e64364f-7b20-4b91-8373-d0ca8db56031"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tyler/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/tyler/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/tyler/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from time import time\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "try:    \n",
    "    from google.colab import files\n",
    "    colab = True  \n",
    "except:\n",
    "    colab = False\n",
    "if colab:\n",
    "    import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "f5Grf4WK0n3i",
    "outputId": "6746d786-fc1d-4c9d-8dd3-aaf6ca4722c9"
   },
   "outputs": [],
   "source": [
    "#if in colab env upload a zip file and extract data to save time.\n",
    "if colab:\n",
    "    files = files.upload()\n",
    "    zip_ref = zipfile.ZipFile('data.zip', 'r')\n",
    "    zip_ref.extractall('./')\n",
    "    zip_ref.close()\n",
    "    print(os.listdir())\n",
    "    train_data = pd.read_csv('./data/train.csv')\n",
    "    test_data = pd.read_csv('./data/test.csv')\n",
    "else:  \n",
    "    train_data = pd.read_csv('./data/train.csv')\n",
    "    test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2STLlOIm0n3p"
   },
   "source": [
    "## Step 1: Analize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "colab_type": "code",
    "id": "UrwKbx-k0n3t",
    "outputId": "3562ee07-2ba4-473f-d4f9-f0fafd4b7245"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([144277.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "              0.,      0.,  15294.]),\n",
       "  array([157976.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "              0.,      0.,   1595.]),\n",
       "  array([151122.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "              0.,      0.,   8449.]),\n",
       "  array([159093.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "              0.,      0.,    478.]),\n",
       "  array([151694.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "              0.,      0.,   7877.]),\n",
       "  array([158166.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "              0.,      0.,   1405.])],\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 6 Lists of Patches objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([train_data['toxic'], train_data['severe_toxic'],train_data['obscene'], train_data['threat'], train_data['insult'], train_data['identity_hate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nF7eMLk50n31"
   },
   "source": [
    "The data is skewed to non negitive comments (left bars). 10% of the rows in the training data contain some sort of negitivity. We're going to need to seperate the data evenly to avoid bias toward non negative comments (right bars).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Du3AIVnO0n33",
    "outputId": "fc6a73d3-8095-47e8-aab6-2bccc414e0f4"
   },
   "outputs": [],
   "source": [
    "def distribute_data(train_data):\n",
    "    negative_rows = []\n",
    "    positive_rows = []\n",
    "    for comment, toxic, severe_toxic, obscene, threat, insult, identity_hate in zip(train_data['comment_text'],train_data['toxic'],train_data['severe_toxic'], train_data['obscene'], train_data['threat'], train_data['insult'], train_data['identity_hate']):\n",
    "        #check for some sort of negitivity in columns\n",
    "        if toxic == severe_toxic == obscene == threat == insult == identity_hate:\n",
    "            positive_rows.append([comment, toxic, severe_toxic, obscene, threat, insult, identity_hate])\n",
    "        else:\n",
    "            negative_rows.append([comment, toxic, severe_toxic, obscene, threat, insult, identity_hate])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #shuffle positive rows\n",
    "    random.shuffle(positive_rows)\n",
    "    #grab sample size of positive comments = to the total amount of negitive comments\n",
    "    positive_rows = positive_rows[:len(negative_rows)]\n",
    "    #combne them into a single list\n",
    "    combine = negative_rows + positive_rows\n",
    "    #shuffle\n",
    "    random.shuffle(combine)\n",
    "    train_data = combine\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZiZsTI20n39"
   },
   "source": [
    "## Step 2: Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. distribute training data evenly between negitive sentiment and non negitive sentiment to avoid bias <br>\n",
    "2. remove all non alphabetic characters. <br>\n",
    "3. Tokenize string into an list EX: \"Machine learning is fun\" -> [\"Machine ,\"learning\", \"is\", \"fun\"] <br>\n",
    "4. Filter stopwords out (commonly used words EX: \"The\") <br>\n",
    "5. lemmatizing words (converting a word to its base form) EX: Caring -> Lemmatization -> Care <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = distribute_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_U-DcGpf0n4A"
   },
   "outputs": [],
   "source": [
    "def preprocess_train(data):\n",
    "    labels = []\n",
    "    comments = []   \n",
    "    stop_words =  set(stopwords.words('english'))       \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #evens out training data to avoid bias    \n",
    "    #preprocess\n",
    "    for line in data:      \n",
    "        line[0] = re.sub('[^A-Za-z\\s]+',  '',line[0])\n",
    "        word_tokens = word_tokenize(line[0])  \n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        processed = \" \".join([lemmatizer.lemmatize(w) for w in filtered_sentence]).lower()\n",
    "        comments.append(processed)\n",
    "        labels.append(line[1:])\n",
    "    return comments,labels\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOkHlZkrDa96"
   },
   "outputs": [],
   "source": [
    "def preprocess_test(data):\n",
    "     \n",
    "    comments = []\n",
    "    stop_words =  set(stopwords.words('english'))       \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    for line in data['comment_text']:   \n",
    "        line = re.sub('[^A-Za-z\\s]+',  '',line)       \n",
    "        word_tokens = word_tokenize(line)  \n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]        \n",
    "        processed = \" \".join([lemmatizer.lemmatize(w) for w in filtered_sentence]).lower()\n",
    "        comments.append(processed)           \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lSxPnFhs0n4J"
   },
   "outputs": [],
   "source": [
    "X_train ,y_train = preprocess_train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MaznJItx0n4Q"
   },
   "outputs": [],
   "source": [
    "X_test = preprocess_test(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "QXKbQmmN0n4d",
    "outputId": "2adba72b-0f44-413c-8dab-bf519ec52309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32388,)\n",
      "(153164,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural net only understands numbers. Hence we need to transform our words into vector representations.\n",
    "\n",
    "We fit <strong>ONLY</strong> on training set and then call texts_to_sequences on both train and test set to transform them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtJ_wfGZ0n4i"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning libraries assume a vectorized representation of your data.\n",
    "\n",
    "In the case of variable length sequence prediction problems, this requires that your data be transformed such that each sequence has the same length.\n",
    "\n",
    "This vectorization allows code to efficiently perform the matrix operations in batch for your chosen deep learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hUUp0Kmb0n4s",
    "outputId": "baa708a2-37c3-462b-ef53-2fcdbfd3a385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 1383)\n",
      "(32388, 1383)\n"
     ]
    }
   ],
   "source": [
    "#get length of the longest sequence\n",
    "max_len = 0\n",
    "for i in X_train:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bn8x9Qdw0n4y"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cd2sPdJr0n43"
   },
   "source": [
    "# Step 3: Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNTdcXXU0n45"
   },
   "outputs": [],
   "source": [
    "#size of our vocabulary to fit into the embedding layer.\n",
    "max_words = len(tokenizer.word_counts) + 1\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    #max_words tells we plan to encode N words in total. 64 tells we use 64 dimensional vector space. max_len tells input documents have N words each.\n",
    "    model.add(Embedding(max_words, 64, input_length=max_len))\n",
    "    #By dropping a unit out, we mean temporarily removing it from the network, along with all its incoming and outgoing connections\n",
    "    model.add(Dropout(0.5))\n",
    "    #a way to reduce the size of incoming vectors In the case of max pooling you take the maximum value of all features in the pool for each feature dimension\n",
    "    model.add(GlobalMaxPool1D())   \n",
    "    #final layer should have as many neurons as classes we're predicting and use sigmoid to return a probability.\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "    #categorical_accuracy checks to see if the index of the maximal true value is equal to the index of the maximal predicted value.\n",
    "    model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Q39BpgVz-v4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "etta1jcP0n49",
    "outputId": "1baa5301-ac0b-45eb-9ba2-61c01f9b88be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25910 samples, validate on 6478 samples\n",
      "Epoch 1/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.3340 - categorical_accuracy: 0.9313 - val_loss: 0.2902 - val_categorical_accuracy: 0.9710\n",
      "Epoch 2/10\n",
      "25910/25910 [==============================] - 61s 2ms/sample - loss: 0.2156 - categorical_accuracy: 0.9712 - val_loss: 0.2547 - val_categorical_accuracy: 0.9707\n",
      "Epoch 3/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.1926 - categorical_accuracy: 0.9694 - val_loss: 0.2429 - val_categorical_accuracy: 0.9676\n",
      "Epoch 4/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.1811 - categorical_accuracy: 0.9620 - val_loss: 0.2344 - val_categorical_accuracy: 0.9535\n",
      "Epoch 5/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.1716 - categorical_accuracy: 0.9438 - val_loss: 0.2343 - val_categorical_accuracy: 0.9196\n",
      "Epoch 6/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.1648 - categorical_accuracy: 0.9198 - val_loss: 0.2275 - val_categorical_accuracy: 0.8878\n",
      "Epoch 7/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.1600 - categorical_accuracy: 0.8990 - val_loss: 0.2248 - val_categorical_accuracy: 0.8899\n",
      "Epoch 8/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.1545 - categorical_accuracy: 0.8778 - val_loss: 0.2209 - val_categorical_accuracy: 0.8668\n",
      "Epoch 9/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.1498 - categorical_accuracy: 0.8572 - val_loss: 0.2226 - val_categorical_accuracy: 0.8129\n",
      "Epoch 10/10\n",
      "25910/25910 [==============================] - 62s 2ms/sample - loss: 0.1460 - categorical_accuracy: 0.8372 - val_loss: 0.2179 - val_categorical_accuracy: 0.8652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f41dfc00c18>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "tensorboard = TensorBoard(log_dir='./toxic_comments')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1,validation_split=0.2, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2YX3V7_0n5J"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9912098 , 0.28100103, 0.9270433 , 0.08639115, 0.85703504,\n",
       "        0.27300724],\n",
       "       [0.01557371, 0.00715369, 0.04015896, 0.02055919, 0.03621644,\n",
       "        0.03473604],\n",
       "       [0.41198945, 0.09073785, 0.16641742, 0.08620602, 0.1912818 ,\n",
       "        0.12949824],\n",
       "       ...,\n",
       "       [0.03472677, 0.00948972, 0.03420067, 0.02417684, 0.04848775,\n",
       "        0.03820086],\n",
       "       [0.15793538, 0.01906985, 0.08302706, 0.04347491, 0.10162637,\n",
       "        0.16091704],\n",
       "       [0.9852358 , 0.16483027, 0.83313644, 0.11681563, 0.6777185 ,\n",
       "        0.19511142]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d35m0rH_0n5Q"
   },
   "outputs": [],
   "source": [
    "kaggle_prediction = pd.DataFrame(columns=['id','toxic','severe_toxic','obscene','threat','insult','identity_hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mRcR7i90n5W"
   },
   "outputs": [],
   "source": [
    "kaggle_prediction['id'] = test_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v4PvX8Pi1d4_",
    "outputId": "7a975b03-e05e-4ffb-8d8b-8d41a0425159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 6)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8DNHpqX0n5b"
   },
   "outputs": [],
   "source": [
    "kaggle_prediction[['toxic','severe_toxic','obscene','threat','insult','identity_hate']] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8ZG4pKR90n5j",
    "outputId": "d5f4b793-9e2e-4794-aa3b-227efcfbabe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VEG7ThH0n5r"
   },
   "outputs": [],
   "source": [
    "kaggle_prediction.to_csv('toxic_comments_prediction_1.csv' ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export for use in applications\n",
    "model.save('toxic_comments.h5')\n",
    "f = open('word_tokenizer', 'wb')\n",
    "pickle.dump(tokenizer, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Toxic Comments Classification - Kaggle Competition.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
